{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CPU_vs_GPU.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOu0_WML14nX"
      },
      "source": [
        "#importing required libraries\r\n",
        "import torch\r\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRULjMbr2Oy7",
        "outputId": "46ef01d1-5f88-4094-f563-e65f5eaee9db"
      },
      "source": [
        "#Initialisation of tensors\r\n",
        "dim=8000\r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "x=torch.randn(dim,dim)\r\n",
        "elapsed_time = time.time() - start_time\r\n",
        "print('CPU_time = ',elapsed_time)\r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "x=torch.randn((dim,dim), device=torch.device(\"cuda:0\"))\r\n",
        "elapsed_time = time.time() - start_time\r\n",
        "print('GPU_time = ',elapsed_time)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU_time =  0.6315245628356934\n",
            "GPU_time =  0.005063533782958984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHHRrsCq3FAl",
        "outputId": "b8fdbcce-0527-4e4d-901f-5aa06b700090"
      },
      "source": [
        "# Matrix Multiplication\r\n",
        "dim=8000\r\n",
        "\r\n",
        "x=torch.randn(dim,dim)\r\n",
        "y=torch.randn(dim,dim)\r\n",
        "start_time = time.time()\r\n",
        "z=torch.matmul(x,y)\r\n",
        "elapsed_time = time.time() - start_time\r\n",
        "print('CPU_time = ',elapsed_time)\r\n",
        "\r\n",
        "\r\n",
        "x=torch.randn(dim,dim,device=torch.device(\"cuda:0\"))\r\n",
        "y=torch.randn(dim,dim,device=torch.device(\"cuda:0\"))\r\n",
        "start_time = time.time()\r\n",
        "z=torch.matmul(x,y)\r\n",
        "elapsed_time = time.time() - start_time\r\n",
        "print('GPU_time = ',elapsed_time)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU_time =  11.078287363052368\n",
            "GPU_time =  0.01821756362915039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ye0fasBN4AxO",
        "outputId": "613b1925-b7d3-4281-fc12-fdbf01bbcdfb"
      },
      "source": [
        "#Element Wise operations (multiplication,addition,subtraction)\r\n",
        "\r\n",
        "dim=8000\r\n",
        "\r\n",
        "x=torch.randn(dim,dim)\r\n",
        "y=torch.randn(dim,dim)\r\n",
        "start_time = time.time()\r\n",
        "a=x*y\r\n",
        "b=x+y\r\n",
        "c=x-y\r\n",
        "elapsed_time = time.time() - start_time\r\n",
        "print('CPU_time = ',elapsed_time)\r\n",
        "\r\n",
        "\r\n",
        "x=torch.randn(dim,dim,device=torch.device(\"cuda:0\"))\r\n",
        "y=torch.randn(dim,dim,device=torch.device(\"cuda:0\"))\r\n",
        "start_time = time.time()\r\n",
        "a=x*y\r\n",
        "b=x+y\r\n",
        "c=x-y\r\n",
        "elapsed_time = time.time() - start_time\r\n",
        "print('GPU_time = ',elapsed_time)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU_time =  0.22835350036621094\n",
            "GPU_time =  0.005945444107055664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HK83oeq4oCU",
        "outputId": "32d04dd7-e56b-439d-e7a9-8061735ead35"
      },
      "source": [
        "#Broadcasting\r\n",
        "dim=8000\r\n",
        "\r\n",
        "device=torch.device(\"cuda:0\")\r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "torch.add(torch.randn(dim,1), torch.randn(dim))\r\n",
        "elapsed_time = time.time() - start_time\r\n",
        "print('CPU_time = ',elapsed_time)\r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "torch.add(torch.randn(dim,1,device=device), torch.randn(dim,device=device))\r\n",
        "elapsed_time = time.time() - start_time\r\n",
        "print('GPU_time = ',elapsed_time)\r\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU_time =  0.052433013916015625\n",
            "GPU_time =  0.0006804466247558594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9zd21J45Xsk",
        "outputId": "46d1ed62-0142-4f65-ddfd-88a10269a07c"
      },
      "source": [
        "#Outer Product of tensors\r\n",
        "\r\n",
        "dim=8000\r\n",
        "\r\n",
        "device=torch.device(\"cuda:0\")\r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "torch.outer(torch.randn(dim), torch.randn(dim))\r\n",
        "elapsed_time = time.time() - start_time\r\n",
        "print('CPU_time = ',elapsed_time)\r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "torch.outer(torch.randn(dim,device=device), torch.randn(dim,device=device))\r\n",
        "elapsed_time = time.time() - start_time\r\n",
        "print('GPU_time = ',elapsed_time)\r\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU_time =  0.05100727081298828\n",
            "GPU_time =  0.0005676746368408203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEVekUQ_6RpO"
      },
      "source": [
        "In all the above tensor operations, GPU is faster as compared to CPU. But if we will reduce the dimension of the tensors a lot, then computation required to do the above operations will be small and very less number of cores will be required. As we know individual core of CPU is powerful than that of GPU. Hence CPU will be equally fast or more fast than GPU in case of low dimensions of tensors  as parallel computation of GPU will be compensated by strength of individual core of CPU.\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "<br><br>\r\n",
        "Let's see one of the above operation (with lower dimension)<br>\r\n",
        "(Just changing the dimension of the tensor)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8AEEnrV57BM",
        "outputId": "26a4b8ee-eeaf-40cd-d220-7f165b7eb838"
      },
      "source": [
        "#Element Wise operations (multiplication,addition,subtraction)\r\n",
        "dim=4\r\n",
        "\r\n",
        "x=torch.randn(dim,dim)\r\n",
        "y=torch.randn(dim,dim)\r\n",
        "start_time = time.time()\r\n",
        "a=x*y\r\n",
        "b=x+y\r\n",
        "c=x-y\r\n",
        "elapsed_time = time.time() - start_time\r\n",
        "print('CPU_time = ',elapsed_time)\r\n",
        "\r\n",
        "\r\n",
        "x=torch.randn(dim,dim,device=torch.device(\"cuda:0\"))\r\n",
        "y=torch.randn(dim,dim,device=torch.device(\"cuda:0\"))\r\n",
        "start_time = time.time()\r\n",
        "a=x*y\r\n",
        "b=x+y\r\n",
        "c=x-y\r\n",
        "elapsed_time = time.time() - start_time\r\n",
        "print('GPU_time = ',elapsed_time)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU_time =  0.00015163421630859375\n",
            "GPU_time =  0.0002722740173339844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP3WA6uv888l"
      },
      "source": [
        "Now, if some task involves recurrence. It must be done sequentially. Hence CPU will be more efficient in such case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S20pawmO8EqP",
        "outputId": "84e6ec2d-b08c-4d0f-8d80-418f71c0a3bc"
      },
      "source": [
        "\r\n",
        "dim=4\r\n",
        "\r\n",
        "x=torch.randn(dim,dim)\r\n",
        "y=torch.randn(dim,dim)\r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "for i in range(100000):\r\n",
        "   x+=x\r\n",
        "elapsed_time = time.time() - start_time\r\n",
        "print(elapsed_time)\r\n",
        "\r\n",
        "\r\n",
        "x=torch.randn(dim,dim,device=torch.device(\"cuda:0\"))\r\n",
        "y=torch.randn(dim,dim,device=torch.device(\"cuda:0\"))\r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "for i in range(100000):\r\n",
        "   x+=x\r\n",
        "elapsed_time = time.time() - start_time\r\n",
        "print(elapsed_time)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.18252229690551758\n",
            "0.5116729736328125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_W9BGNS90ns"
      },
      "source": [
        "we have 1000000 operations, but due to the structure of the code it is impossible to parallelize much of these computations because to compute the next x you need to know the value of the previous (or current) x. We only can parallelize 16 operations (additions) per iteration. As the CPU has few, but much more powerful cores, it is  faster for the given example!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6xcA8fg9wpW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}